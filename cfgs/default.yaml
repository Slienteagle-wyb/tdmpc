# environment
task: hopper-hop
modality: 'state'
action_repeat: ???
discount: 0.99
episode_length: 1000/${action_repeat}
train_steps: 500000/${action_repeat}

# planning
iterations: 6
num_samples: 256 # 256 for icem, 512 default
num_elites: 32  # 32 for icem, 64 default
mixture_coef: 0.5  # 0.05
min_std: 0.05
temperature: 0.5
momentum: 0.1
init_std: 0.5

# icem
factor_decrease_num: 1.25
shift_elites_over_time: true
fraction_elites_reused: 0.25
keep_previous_elites: true
noise_beta: 2.5

# learning
batch_size: 512
max_buffer_size: 1000000
horizon: 6
warmup_len: 0
similarity_horizon: 1
reward_coef: 0.5  # 0.2 for mujoco, 0.5 for dm_control
value_coef: 0.1  # 0.1 default
consistency_coef: 0.5  # 2.0 for mlp, 0.4 for drnn
similarity_coef: 1.0  # 0.2 drnn, 1.0 mlp
intrinsic_reward_coef: 0.5  # 0.002 for quad, 0.5 for dm_control
rho: 1.0
td_lambda: 0.4
kappa: 0.1
per_alpha: 0.6
per_beta: 0.4
grad_clip_norm: 10
update_freq: 2
tau: 0.01
std_schedule: linear(0.5, ${min_std}, 25000, 0)  # duration 25000 train step
horizon_schedule: linear(2, ${horizon}, 25000, 0)
regularization_schedule: linear(0.05, ${mixture_coef}, 1, 5000)
seed_steps: 5000
explore_schedule: linear(0, ${intrinsic_reward_coef}, 25000, 5000)

# finetune
pretrained_seed: 1932  # the seed of pretrained model
freeze_encoder: false
demo_schedule: linear(0.95, 0.25, 30000, 20000)

# cql
cql_n_actions: 10
cql_tmp: 1.0
cql_min_q_weight: 1.0  # 1.0
cql_target_action_gap: 10 # 10.0
alpha_lr: 1e-4

# optim
lr: 1e-3
pi_lr: 1e-3
temp_lr: 3e-4
q_lr: 1e-3
optim_id: 'adamw'
weight_decay: 0.0

# architecture
enc_dim: 256  # 256
mlp_dim: 512  # 512
latent_dim: 50  # 50
hidden_dim: 128  # 128
norm_cell: true

# wandb (insert your own)
use_wandb: true
wandb_project: MoPAC
wandb_entity: Slientea98
wandb_exp_name: 0630_(drnn_no_shoot)_icem_color2.5_rho1.0_explore0.5(5/25)_td_lambda0.4_all_weights_equal

# mis
seed: 4245
train_interval: 1
env_horizon: 0  # 0 if normal transition
dream_horizon : 1
dream_trace: 8
exp_name: default
eval_freq: 20000
eval_freq_episodes: 20
eval_episodes: 10
save_video: false
save_model: true
device: 'cuda'
normalize: true
norm_type: 'ln'
model_path: 'models/model.pt'  #checkpoint_1000
save_interval: 200 # count in epoch

# sac
gamma: 0.99
sac_tau: 0.005
latent_policy: false

# plan2expl
plan2expl: false
ensemble_lr: 3e-4
num_ensembles: 5
#sched_kwargs:
#  sched_id: 'cosine'
#  min_lr: 1e-4
#  warmup_lr_init: 1e-5
#  warmup_epochs: 20